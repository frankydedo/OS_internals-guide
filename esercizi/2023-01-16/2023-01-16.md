# Esercizio 1

*Sia dato un sistema di memoria virtuale con paginazione, nel quale vengono indirizzati i Byte. Il sistema dispone di TLB (Translation Look-aside Buffer), su cui si misura sperimentalmente un “hit ratio” del 90%. La tabella delle pagine (“page-table”) viene realizzata con uno schema a due livelli, nel quale un indirizzo logico di 64 bit viene suddiviso (da MSB a LSB) in 3 parti: p1, p2 e d, rispettivamente di 40 bit, 12 bit e 12 bit. Non si utilizzano ulteriori strutture dati (quali tabelle di hash o inverted page table) per velocizzare gli accessi. La memoria virtuale viene gestita con paginazione a richiesta.*

## A

*Supponendo che non sia presente una memoria cache, e che la memoria RAM abbia tempo di accesso di 200 ns, si calcoli il tempo effettivo di accesso (EAT) per il caso proposto (TLB hit ratio = 90%), assumendo che il tempo di accesso alla TLB sia trascurabile.*

Per calcolare EAT consideriamo i due casi:

- traduzione logico->fisico presente in TLB (90% dei casi)
  - moltiplichiamo il tempo di accesso fornito per 0.9
- traduzione logico->fisico *NON* presente in TLB (10% dei casi)
  - accediamo alla *page table* (presente in RAM) una volta per ogni livello che la compone (in questo caso 2) per recuperare l'indirizzo fisico. a questo punto possiamo accedere in RAM per recuperare il dato. (3 accessi totali in questo caso). moltiplichiamo il tempo di accesso fornito per 0.1.

### Risultato finale:

    EAT = hit_ratio⋅t_ram + (1−hit_ratio) ⋅ (3⋅t_ram) = 240 ns

## B

*Si vuole ora tener conto del fatto che il sistema dispone di memoria cache, per la quale si sa che la probabilità di (cache) miss è del 10% (un accesso non in cache ogni 10) e che la cache ha tempo di accesso 30 ns.
Si ricalcoli EAT, con gli stessi dati per quanto riguarda la TLB e ipotizzando, nel caso di cache miss, un tempo di accesso alla RAM di 230 ns.*

Per calcolare il nuovo EAT bisogna prima calcolare il **tempo medio per un accesso ai dati**.

Distinguiamo i due possibili casi:

- cache hit (90%)
  - tempo di accesso 30 ns.
- cache miss (10%)
  - il tempo di accesso in questo caso è dato dal tempo di accesso alla cache (30 ns) a cui bisogna aggiungere il tempo di accesso alla RAM (200 ns). Chiameremo questo tempo **t_cache_ram** *= t_cache + t_ram*.

**Tempo medio per un accesso ai dati (avg_t_data)**:

    avg_t_data = cache_hit_ratio⋅t_cache + (1-cache_hit_ratio)⋅t_cache_ram = 50 ns

A questo punto possiamo calcolare il nuovo EAT iterando quanto fatto nel punto A:

- TLB hit (90%)
  - 1 accesso -> 50 ns
- TLB miss (10%)
  - 3 accessi -> 3⋅50 ns = 150 ns

### Risultato finale

    EAT = hit_ratio⋅avg_t_data + (1−hit_ratio)⋅(3⋅avg_t_data) = 60 ns

## C

*Si consideri ora la frequenza di page fault p. Si faccia riferimento al caso della domanda B (presenza di cache) e si ipotizzi che un page fault sia gestito in 5 ms. Quanto deve valere p affinché si possa garantire un degrado massimo del 25% per EAT (causato sia dalla TLB che dai page fault)?
Si tratta di un valore massimo o minimo per p?*

In questo caso vogliamo il valore massimo di **p** (frequenza di page fault) affinché l’EAT cresca al massimo del 25% rispetto al valore calcolato nella domanda B (ovvero 60 ns).

    EAT_max = EAT⋅1,25 = 75 ns

Alla luce di quanto spiegato in precedenza, e considerato il tempo di recovery di 5ms = 5.000.000 ns, è facilmente deducibile che:

    EAT = (1-p)⋅60 ns + p⋅5.000.000

siccome vogliamo:

    EAT < EAT_max

    otteniamo:

    (1-p)⋅60 ns + p⋅5.000.000 ≤ 75 ns

risolvendo per p:

    p ≤ 3 ⋅ 10^-6

# Esercizio 2

*Sia dato un file di dimensione 160MB, in un file system di dimensione complessiva 400GB. Si vogliono confrontare le possibili organizzazioni di tale file, su file system con allocazione non contigua, secondo gli schemi:*

- *“linked list allocation”*
- *“File Allocation Table (FAT)”*

*Si supponga che i blocchi su disco (sia per i dati che per metadati) abbiano dimensione 8KB, e che i puntatori e gli indici abbiano dimensione 32 bit.
Si dica, per ognuna delle 2 soluzioni:*

## A

*Quanti blocchi (di dato e/o di metadato) sono necessari per il file (attenzione: Si richiede il conteggio ESATTO, eventualmente espresso in termini di potenze di 2, ricordando che 1K = 2^10 e 1M = 2^20!)?
Nel caso della FAT, si dica quale percentuale di FAT è utilizzata per il file.*

Per risolvere questo quesito è sufficiente considerare che:

- *linked list allocation*
  - ogni blocco (8 KB) deve contenere 4 B di puntatore all'elemento successivo della lista, mentre il resto è di dato.
- *FAT*
  - tutti gli 8 KB sono di dato.

Quindi abbiamo:

    #Blocchi = dim. file / dati in un blocco

    da cui:

    #blocchi_linked_list_allocation = 160 MB / (8 KB - 4B) = 20.491 blocchi

    #blocchi_fat = 160 MB / 8 KB = 20.480 blocchi

Per calcolare la percentuale di FAT utilizzata per il file basta fare:

    dim. file /  dim. FAT

    da cui:

    160 MB / 400 GB = 0.04%

## B

*Quante letture in RAM e quanti accessi a disco (per trasferire un blocco in RAM) sono necessari per leggere il byte n. 42070 all’interno del file? Si consideri un accesso diretto a file. Si supponga di non utilizzare buffer cache, e che un puntatore o indice venga letto in RAM con una sola lettura. Si supponga poi che il File Control Block (FCB) sia già in memoria RAM, che ogni accesso a disco legga o scriva un blocco di 8KB, e che la FAT (qualora utilizzata) sia già in RAM.*

### linked list allocation

#### Step 1

Per capire quante letture in ram e su disco sono necessarie ad accedere al byte n. 42070 dobbiamo innanzitutto capire in quale blocco si trova. 

Ricordiamoci che nella *linked list allocation* i blocchi non contengono esclusivamente dati, bensì abbiamo 4 B di puntatore al blocco successivo.
Siccome in questo caso abbiamo *8192 B - 4 B =* **8188 B di dati**.

    #blocco = 42070 / 8188 = 5.15 

    arrotondiamo all'intero inferiore e otteniamo blocco #5.

**NB**: il blocco #5 è il **sesto** blocco.

#### Step 2

Ora sappiamo che dobbiamo arrivare al blocco #5, e per farlo nel caso della *linked list allocation* per ogni blocco dobbiamo:

- fare 1 accesso su disco per recuperare l'*i-esimo* blocco -> 6 accessi
- trasferire il suddetto blocco in ram e leggerlo (1 accesso in ram) -> 5 accessi per i puntatori + 1 accesso per i dati del blocco che ci interessa 

In questo caso avremo quindi 6 accessi su disco (1 per ogni blocco da 'scorrere') e 6 accessi in ram (5 volte per leggere il puntatore al blocco successivo, e 1 volta per leggere la parte dati desiderata).

### FAT

#### Step 1

Analogo a quanto detto in precedenza, con l'unica differenza che in questo caso il blocco contiene esclusivamente dati.

    #blocco = 42070 / 8192 = 5.13

    arrotondiamo all'intero inferiore e otteniamo blocco #5.

#### Step 2

Nel caso della *FAT*, supponendo che questa risieda già in ram come da indicazioni, per ogni blocco dobbiamo:

- fare 1 accesso in ram per recuperare il primo puntatore al FCB
- fare 1 accesso in ram per ogni puntatore da scorrere -> 5 accessi
- fare 1 accesso su disco per recuperare il blocco a cui siamo interessati 
- fare un ulteriore accesso alla ram per leggere il blocco appena trasferito dal disco

In totale avremo quindi:

- 7 accessi alla ram
- 1 accesso al disco

# Esercizio 3

*Si consideri un sistema con paginazione. Si dica, per ognuna delle caratteristiche elencate, se sia preferibile una dimensione di pagina maggiore o minore, motivando la risposta.*

- *Frammentazione*
- *Dimensione PT*
- *Sovraccarico I/O*
- *Numero di errori di pagina*
- *Località*
- *Dimensioni/copertura TLB*

||Meglio dimensione minore|Meglio dimensione maggiore|
| :--: | :-- | :-- |
|**Frammentazione**|la frammentazione interna è minore con pagine piccole, perché lo spazio sprecato all'interno dell'ultima pagina è proporzionalmente inferiore.||
|**Dimensione della Page Table**||con pagine più grandi, serve un numero minore di pagine per rappresentare lo stesso spazio di indirizzamento, quindi anche una page table più piccola.|
|**Overhead I/O**||caricare una pagina grande permette di portare più dati in memoria con ogni operazione I/O, riducendo il numero complessivo di accessi al disco.|
|**Numero di page fault**||se la località è rispettata, ogni pagina contiene più dati utili e quindi riduce la probabilità di incorrere in un nuovo page fault.|
|**Località**|Se il programma ha una ***bassa località*** allora avere pagine grandi porta in memoria dati inutili.|Se il programma ha un'***alta località*** conviene avere pagine grandi così da portare in memoria quanti più dati utili possibile in meno trasferimenti. |
|**Dimensioni / Copertura del TLB**||il TLB può memorizzare un numero fisso di voci. Se le pagine sono più grandi, ogni voce TLB copre più memoria, migliorando la copertura del TLB.|

# Esercizio 5

*Si consideri, in OS161, la realizzazione della gestione della memoria virtuale. Si risponda alle seguenti domande:*

## A
*Si supponga di voler realizzare in dumbvm la gestione dei frame liberi mediante free-list, invece che con bitmap (come fatto nella soluzione proposta per il lab 2).*

### A1
*Si dica se la free list può essere una lista non ordinata oppure se deve essere ordinata. (motivare)*

Nel contesto di OS/161 e in particolare del gestore di memoria virtuale *dumbvm*, una **free list** serve a tenere traccia dei frame liberi in RAM (cioè delle pagine fisiche disponibili). È un'alternativa alla rappresentazione con *bitmap*, dove ogni bit rappresenta lo stato libero/occupato di un frame.

| Tipo di Lista | PROs | CONs |
| :--: | :-- | :-- |
| **Lista non ordinata** | - **Facile implementazione**  <br> - Operazione di **aggiunta immediata** (O(1)) | - **Ricerca** di frame contigui ha un **costo quadratico** (O(n^2)) <br>|
| **Lista ordinata per indirizzi fisici** | - **Ricerca** di frame contigui ha un **costo lineare** (O(n)) <br> - Prevedibilità nell’allocazione | - Inserimento ha costo O(n)|

### A2

*Qualora la lista fosse ordinata, andrebbe ordinata in base a indirizzi fisici oppure logici? (motivare)*

Ordinare per indirizzi logici invece non ha senso: l'indirizzo logico dipende dai processi e cambia con la mappatura; la free list gestisce frame fisici, quindi l'ordinamento logico è irrilevante.

## B (da rivedere)

*Si suppone di voler realizzare una Page Table (PT) per ogni processo, con le seguenti ipotesi:*

- *Ogni entry della PT occupa 2 Byte.*
- ***NON** si gestisce un heap -> il processo contiene solo:*
  - *Codice*
  - *Dati*
  - *Stack*

*Informazioni fornite*:

- *PAGE_SIZE = 4096 byte (cioè 4 KB)*
- *Segmento codice:*
  - *Inizio: 0x400*
  - *Dimensione: 10112 byte*
- *Segmento dati:*
  - *Inizio: 0x412000*
  - *Dimensione: 8028 byte*
- *Stack: 18 pagine, collocate ai massimi indirizzi logici possibili*

### B1

*Si calcoli la dimensione complessiva dell’address space e, al suo interno, il numero di pagine effettivamente usate (valide).*

#### CALCOLO DELLE PAGINE USATE

1. **CODICE**

- Inizio: 0x400
- Dimensione: 10112 byte


      pagine_codice = dim / PAGE_SIZE = 10112 / 4096 = 2,47 --intero superiore--> 3

2. **DATI**

- Inizio: 0x412000
- Dimensione: 8028 byte


      pagine_dati = dim / PAGE_SIZE = 8028 / 4096 = 1,96 --intero superiore--> 2

3. **STACK**

- Dimensione 18 pagine (fornito tra i dati)

      totale_pagine = 3+2+18 = 23

#### CALCOLO ADDRESS SPACE

Per calcolare l'address space totale dobbiamo capire com'è organizzato la memoria. Dalla capiamo che lo stack **cresce verso il basso** partendo dagli indirizzi più significativi. Possiamo quindi immaginare la memoria come segue:

**INDIRIZZI PIU' SIGNIFICATIVI**

Inizio dello Stack    --> 0xFFFFFFFF
.
.
.
Fine dello Stack      --> ???

**INDIRIZZI MENO SIGNIFICATIVI**